---
- name: KubeSphere | Setting Kubernetes version
  set_fact:
    kube_version: "{{ kubernetes_version }}"
  failed_when: false


- name: KubeSphere | Getting Kubernetes master num
  shell: >
    {{ bin_dir }}/kubectl get node | awk '{if(NR>1){print $3}}' | grep master |wc -l
  register: masters
  failed_when: false


- name: KubeSphere | Setting master num
  set_fact:
    master_num: "{{ masters.stdout }}"
  failed_when: false

- name: KubeSphere | Override master num
  set_fact:
    master_num: "3"
  failed_when: false
  when:
    - master_num is defined and (master_num == "1" or master_num == "0")
    - enableHA is defined and enableHA

- name: KubeSphere | Setting enableHA
  set_fact:
    enableHA: >-
      {% if masters is defined and masters.stdout is defined and masters.stdout != "0" and masters.stdout != "1" %}true{% else %}false{% endif %}
  when:
    - enableHA is not defined

- name: KubeSphere | Checking ks-core Helm Release
  shell: >
    {{ bin_dir }}/kubectl -n kubesphere-system get secrets --field-selector=type=helm.sh/release.v1  | grep ks-core |wc -l
  register: helm_release

- name: KubeSphere | Checking ks-core Exsit
  shell: >
    {{ bin_dir }}/kubectl get crd users.iam.kubesphere.io  | grep users.iam.kubesphere.io |wc -l
  register: ks_crds

- name: KubeSphere | Convert ks-core to helm mananged
  shell: >
    {{ bin_dir }}/kubectl -n {{ item.ns }} annotate --overwrite {{ item.kind }} {{ item.resource }} meta.helm.sh/release-name={{ item.release }} &&
    {{ bin_dir }}/kubectl -n {{ item.ns }} annotate --overwrite {{ item.kind }} {{ item.resource }} meta.helm.sh/release-namespace=kubesphere-system &&
    {{ bin_dir }}/kubectl -n {{ item.ns }} label --overwrite {{ item.kind }} {{ item.resource }} app.kubernetes.io/managed-by=Helm
  loop:
    - {ns: "kubesphere-controls-system", kind: "serviceaccounts", resource: "kubesphere-cluster-admin", release: "ks-core"}
    - {ns: "kubesphere-controls-system", kind: "serviceaccounts", resource: "kubesphere-router-serviceaccount", release: "ks-core"}
    - {ns: "kubesphere-controls-system", kind: "role", resource: "system:kubesphere-router-role", release: "ks-core"}
    - {ns: "kubesphere-controls-system", kind: "rolebinding", resource: "nginx-ingress-role-nisa-binding", release: "ks-core"}
    - {ns: "kubesphere-controls-system", kind: "deployment", resource: "default-http-backend", release: "ks-core"}
    - {ns: "kubesphere-controls-system", kind: "service", resource: "default-http-backend", release: "ks-core"}
    - {ns: "kubesphere-system", kind: "secrets", resource: "ks-controller-manager-webhook-cert", release: "ks-core"}
    - {ns: "kubesphere-system", kind: "serviceaccounts", resource: "kubesphere", release: "ks-core"}
    - {ns: "kubesphere-system", kind: "configmaps", resource: "ks-console-config", release: "ks-core"}
    - {ns: "kubesphere-system", kind: "configmaps", resource: "ks-router-config", release: "ks-core"}
    - {ns: "kubesphere-system", kind: "configmaps", resource: "sample-bookinfo", release: "ks-core"}
    - {ns: "kubesphere-system", kind: "clusterroles", resource: "system:kubesphere-router-clusterrole", release: "ks-core"}
    - {ns: "kubesphere-system", kind: "clusterrolebindings", resource: "system:nginx-ingress-clusterrole-nisa-binding", release: "ks-core"}
    - {ns: "kubesphere-system", kind: "clusterrolebindings", resource: "system:kubesphere-cluster-admin", release: "ks-core"}
    - {ns: "kubesphere-system", kind: "clusterrolebindings", resource: "kubesphere", release: "ks-core"}
    - {ns: "kubesphere-system", kind: "services", resource: "ks-apiserver", release: "ks-core"}
    - {ns: "kubesphere-system", kind: "services", resource: "ks-console", release: "ks-core"}
    - {ns: "kubesphere-system", kind: "services", resource: "ks-controller-manager", release: "ks-core"}
    - {ns: "kubesphere-system", kind: "deployments", resource: "ks-apiserver", release: "ks-core"}
    - {ns: "kubesphere-system", kind: "deployments", resource: "ks-console", release: "ks-core"}
    - {ns: "kubesphere-system", kind: "deployments", resource: "ks-controller-manager", release: "ks-core"}
    - {ns: "kubesphere-system", kind: "validatingwebhookconfigurations", resource: "users.iam.kubesphere.io", release: "ks-core"}
    - {ns: "kubesphere-system", kind: "validatingwebhookconfigurations", resource: "resourcesquotas.quota.kubesphere.io", release: "ks-core"}
    - {ns: "kubesphere-system", kind: "validatingwebhookconfigurations", resource: "network.kubesphere.io", release: "ks-core"}
    - {ns: "kubesphere-system", kind: "users.iam.kubesphere.io", resource: "admin", release: "ks-core"}
  when:
    - helm_release.stdout == "0" and ks_crds.stdout != "0"
  register: source_state
  failed_when: "source_state.stderr and 'NotFound' not in source_state.stderr"

- name: KubeSphere | Patch admin user
  shell: >
    {{ bin_dir }}/kubectl annotate --overwrite users.iam.kubesphere.io admin helm.sh/resource-policy=keep
  when:
    - ks_crds.stdout != "0"
  failed_when: false

- name: KubeSphere | Getting ks-core helm charts
  copy:
    src: "{{ item }}"
    dest: "{{ kubesphere_dir }}/"
  loop:
    - "ks-core"


- name: KubeSphere | Checking KubeSphere Admin User
  shell: >
    {{ bin_dir }}/kubectl get user.iam.kubesphere.io admin --no-headers | wc -l
  register: kubesphere_admin_user

- name: KubeSphere | Generate init admin password
  block:
    - set_fact:
        adminPassword: >-
          {% if authentication.adminPassword is defined and authentication.adminPassword == "" -%}
          {{ lookup('password', '/dev/null chars=ascii_letters,digits length=16') }}
          {%- elif authentication.adminPassword is defined and authentication.adminPassword != "" -%}
          {{ authentication.adminPassword }}
          {%- else -%}

          {%- endif %}
    - shell: >
        {{ bin_dir }}/kubectl -n kubesphere-system patch secret kubesphere-secret -p '{"data": {"initAdminPassword": "{{ adminPassword | b64encode }}"}}'
      when:
        - adminPassword != ""
  when:
    - kubesphere_admin_user.stdout != "1"

- name: KubeSphere | Creating manifests
  template:
    src: "{{ item.file }}.j2"
    dest: "{{ kubesphere_dir }}/{{ item.path }}/{{ item.file }}"
  with_items:
    - { path: ks-core, file: custom-values-ks-core.yaml}


- name: KubeSphere | Upgrade CRDs
  shell: "{{ bin_dir }}/kubectl apply -f {{ item }}"
  ignore_errors: false
  with_fileglob:
    - "{{ kubesphere_dir }}/ks-core/crds/*"

- name: KubeSphere | Creating ks-core
  shell: >
    {{ bin_dir }}/helm upgrade --install ks-core
    {{ kubesphere_dir }}/ks-core/
    -f {{ kubesphere_dir }}/ks-core/custom-values-ks-core.yaml
    --namespace kubesphere-system
  # register: source_state
  # failed_when: "source_state.stderr and 'already exists' not in source_state.stderr"

- name: KubeSphere | Creating manifests
  template:
    src: "{{ item.file }}.j2"
    dest: "{{ kubesphere_dir }}/{{ item.file }}"
  with_items:
    - { path: ks-core, file: ks-upgrade.yaml }

- name: Kubesphere | Checking Users Manger and Workspaces Manger
  shell: >
    {{ bin_dir }}/kubectl get globalroles.iam.kubesphere.io users-manager workspaces-manager --no-headers | wc -l
  register: manager_result

- name: Kubesphere | Checking migration job
  shell: >
    {{ bin_dir }}/kubectl delete -f {{ kubesphere_dir }}/ks-upgrade.yaml
  when:
    - manager_result.stdout != "0"
  failed_when: false

- name: KubeSphere | Creating migration job
  shell: >
    {{ bin_dir }}/kubectl apply -f {{ kubesphere_dir }}/ks-upgrade.yaml
  when:
    - manager_result.stdout != "0"

- name: KubeSphere | Importing ks-core status
  shell: >
    {{ bin_dir }}/kubectl patch cc ks-installer
    --type merge
    -p '{"status": {"core": {"status": "enabled", "enabledTime": "{{ lookup('pipe','date  +%Y-%m-%dT%H:%M:%S%Z') }}"}}}'
    -n kubesphere-system
  register: cc_result
  failed_when: "cc_result.stderr and 'Warning' not in cc_result.stderr"
  until: cc_result is succeeded
  retries: 5
  delay: 3
