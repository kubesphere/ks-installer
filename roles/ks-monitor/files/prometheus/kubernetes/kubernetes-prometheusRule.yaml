apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  labels:
    app.kubernetes.io/name: kube-prometheus
    app.kubernetes.io/part-of: kube-prometheus
    prometheus: k8s
    role: alert-rules
  name: prometheus-k8s-rules
  namespace: kubesphere-monitoring-system
spec:
  groups:
  - name: k8s.rules
    rules:
    - expr: |
        sum (irate(container_cpu_usage_seconds_total{job="kubelet", image!="", container!=""}[5m]) * on(namespace, cluster) group_left(workspace) kube_namespace_labels{job="kube-state-metrics"}) by (namespace, workspace, cluster)
        or on(namespace, workspace, cluster) max by(namespace, workspace, cluster) (kube_namespace_labels * 0)
      record: namespace:container_cpu_usage_seconds_total:sum_rate
    - expr: |
        sum(container_memory_usage_bytes{job="kubelet", image!="", container!=""} * on(namespace, cluster) group_left(workspace) kube_namespace_labels{job="kube-state-metrics"}) by (namespace, workspace, cluster)
        or on(namespace, workspace, cluster) max by(namespace, workspace, cluster) (kube_namespace_labels * 0)
      record: namespace:container_memory_usage_bytes:sum
    - expr: |
        sum(container_memory_working_set_bytes{job="kubelet", image!="", container!=""} * on(namespace, cluster) group_left(workspace) kube_namespace_labels{job="kube-state-metrics"}) by (namespace, workspace, cluster)
        or on(namespace, workspace, cluster) max by(namespace, workspace, cluster) (kube_namespace_labels * 0)
      record: namespace:container_memory_usage_bytes_wo_cache:sum
    - expr: |
        sum by (namespace, label_name, cluster) (
            sum(kube_pod_container_resource_requests{resource="memory", job="kube-state-metrics"} * on (endpoint, instance, job, namespace, pod, service, cluster) group_left(phase) (kube_pod_status_phase{phase=~"Pending|Running"} == 1)) by (namespace, pod, cluster)
          * on (namespace, pod, cluster)
            group_left(label_name) kube_pod_labels{job="kube-state-metrics"}
        )
      record: namespace_memory:kube_pod_container_resource_requests:sum
    - expr: |
        sum by (namespace, label_name, cluster) (
            sum(kube_pod_container_resource_requests{resource="cpu", job="kube-state-metrics"} * on (endpoint, instance, job, namespace, pod, service, cluster) group_left(phase) (kube_pod_status_phase{phase=~"Pending|Running"} == 1)) by (namespace, pod, cluster)
          * on (namespace, pod, cluster)
            group_left(label_name) kube_pod_labels{job="kube-state-metrics"}
        )
      record: namespace_cpu:kube_pod_container_resource_requests:sum
  - name: node.rules
    rules:
    - expr: |
        sum (node_cpu_seconds_total{job="node-exporter", mode=~"user|nice|system|iowait|irq|softirq"}) by (cpu, instance, job, namespace, pod, cluster)
      record: node_cpu_used_seconds_total
    - expr: |
        max by (namespace,pod,node,owner_name,owner_kind,qos, cluster)(kube_pod_info{job="kube-state-metrics"}
          * on (namespace, pod, cluster) group_left(owner_kind, owner_name) kube_pod_owner{job="kube-state-metrics"}
          * on (namespace,pod, cluster) group_left(qos) max by (namespace,pod,qos, cluster)
            ((label_replace(container_memory_working_set_bytes{job="kubelet", container="",pod!="",id=~".*(burstable|besteffort).*"},"qos","$1","id",".*(burstable|besteffort).*")
            or label_replace(container_memory_working_set_bytes{job="kubelet", container="",pod!="",id!~".*(burstable|besteffort).*"},"qos","guaranteed","id",".*")) > bool 0))
      record: 'qos_owner_node:kube_pod_info:'
    - expr: |
        max(kube_pod_info{job="kube-state-metrics"} * on(node, cluster) group_left(role) kube_node_role{job="kube-state-metrics", role="master"} or on(pod, namespace, cluster) kube_pod_info{job="kube-state-metrics"}) by (node, namespace, host_ip, role, pod, cluster)
      record: 'node_namespace_pod:kube_pod_info:'
    - expr: |
        count by (node, host_ip, role, cluster) (sum by (node, cpu, host_ip, role, cluster) (
          node_cpu_seconds_total{job="node-exporter"}
        * on (namespace, pod, cluster) group_left(node, host_ip, role)
          node_namespace_pod:kube_pod_info:
        ))
      record: node:node_num_cpu:sum
    - expr: |
        avg by(cluster) (irate(node_cpu_used_seconds_total{job="node-exporter"}[5m]))
      record: :node_cpu_utilisation:avg1m
    - expr: |
        avg by (node, host_ip, role, cluster) (
          irate(node_cpu_used_seconds_total{job="node-exporter"}[5m])
        * on (namespace, pod, cluster) group_left(node, host_ip, role)
          node_namespace_pod:kube_pod_info:)
      record: node:node_cpu_utilisation:avg1m
    - expr: |
        1 -
        sum by(cluster) (node_memory_MemFree_bytes{job="node-exporter"} + node_memory_Cached_bytes{job="node-exporter"} + node_memory_Buffers_bytes{job="node-exporter"} + node_memory_SReclaimable_bytes{job="node-exporter"})
        /
        sum by(cluster) (node_memory_MemTotal_bytes{job="node-exporter"})
      record: ':node_memory_utilisation:'
    - expr: |
        sum by (node, host_ip, role, cluster) (
          (node_memory_MemFree_bytes{job="node-exporter"} + node_memory_Cached_bytes{job="node-exporter"} + node_memory_Buffers_bytes{job="node-exporter"} + node_memory_SReclaimable_bytes{job="node-exporter"})
          * on (namespace, pod, cluster) group_left(node, host_ip, role)
            node_namespace_pod:kube_pod_info:
        )
      record: node:node_memory_bytes_available:sum
    - expr: |
        sum by (node, host_ip, role, cluster) (
          node_memory_MemTotal_bytes{job="node-exporter"}
          * on (namespace, pod, cluster) group_left(node, host_ip, role)
            node_namespace_pod:kube_pod_info:
        )
      record: node:node_memory_bytes_total:sum
    - expr: |
        1 - (node:node_memory_bytes_available:sum / node:node_memory_bytes_total:sum)
      record: 'node:node_memory_utilisation:'
    - expr: |
        sum by (node, host_ip, role, cluster) (
          irate(node_disk_reads_completed_total{job="node-exporter"}[5m])
        * on (namespace, pod, cluster) group_left(node, host_ip, role)
          node_namespace_pod:kube_pod_info:
        )
      record: node:data_volume_iops_reads:sum
    - expr: |
        sum by (node, host_ip, role, cluster) (
          irate(node_disk_writes_completed_total{job="node-exporter"}[5m])
        * on (namespace, pod, cluster) group_left(node, host_ip, role)
          node_namespace_pod:kube_pod_info:
        )
      record: node:data_volume_iops_writes:sum
    - expr: |
        sum by (node, host_ip, role, cluster) (
          irate(node_disk_read_bytes_total{job="node-exporter"}[5m])
        * on (namespace, pod, cluster) group_left(node, host_ip, role)
          node_namespace_pod:kube_pod_info:
        )
      record: node:data_volume_throughput_bytes_read:sum
    - expr: |
        sum by (node, host_ip, role, cluster) (
          irate(node_disk_written_bytes_total{job="node-exporter"}[5m])
        * on (namespace, pod, cluster) group_left(node, host_ip, role)
          node_namespace_pod:kube_pod_info:
        )
      record: node:data_volume_throughput_bytes_written:sum
    - expr: |
        sum by(cluster) (irate(node_network_receive_bytes_total{job="node-exporter",device!~"veth.+"}[5m])) +
        sum by(cluster) (irate(node_network_transmit_bytes_total{job="node-exporter",device!~"veth.+"}[5m]))
      record: :node_net_utilisation:sum_irate
    - expr: |
        sum by (node, host_ip, role, cluster) (
          (irate(node_network_receive_bytes_total{job="node-exporter",device!~"veth.+"}[5m]) +
          irate(node_network_transmit_bytes_total{job="node-exporter",device!~"veth.+"}[5m]))
        * on (namespace, pod, cluster) group_left(node, host_ip, role)
          node_namespace_pod:kube_pod_info:
        )
      record: node:node_net_utilisation:sum_irate
    - expr: |
        sum by (node, host_ip, role, cluster) (
          irate(node_network_transmit_bytes_total{job="node-exporter",device!~"veth.+"}[5m])
        * on (namespace, pod, cluster) group_left(node, host_ip, role)
          node_namespace_pod:kube_pod_info:
        )
      record: node:node_net_bytes_transmitted:sum_irate
    - expr: |
        sum by (node, host_ip, role, cluster) (
          irate(node_network_receive_bytes_total{job="node-exporter",device!~"veth.+"}[5m])
        * on (namespace, pod, cluster) group_left(node, host_ip, role)
          node_namespace_pod:kube_pod_info:
        )
      record: node:node_net_bytes_received:sum_irate
    - expr: |
        sum by(node, host_ip, role, cluster) (sum(max(node_filesystem_files{device=~"/dev/.*", device!~"/dev/loop\\d+", job="node-exporter"}) by (device, pod, namespace, cluster)) by (pod, namespace, cluster) * on (namespace, pod, cluster) group_left(node, host_ip, role) node_namespace_pod:kube_pod_info:)
      record: 'node:node_inodes_total:'
    - expr: |
        sum by(node, host_ip, role, cluster) (sum(max(node_filesystem_files_free{device=~"/dev/.*", device!~"/dev/loop\\d+", job="node-exporter"}) by (device, pod, namespace, cluster)) by (pod, namespace, cluster) * on (namespace, pod, cluster) group_left(node, host_ip, role) node_namespace_pod:kube_pod_info:)
      record: 'node:node_inodes_free:'
    - expr: |
        sum by (node, host_ip, role, cluster) (node_load1{job="node-exporter"} * on (namespace, pod, cluster) group_left(node, host_ip, role) node_namespace_pod:kube_pod_info:) / node:node_num_cpu:sum
      record: node:load1:ratio
    - expr: |
        sum by (node, host_ip, role, cluster) (node_load5{job="node-exporter"} * on (namespace, pod, cluster) group_left(node, host_ip, role) node_namespace_pod:kube_pod_info:) / node:node_num_cpu:sum
      record: node:load5:ratio
    - expr: |
        sum by (node, host_ip, role, cluster) (node_load15{job="node-exporter"} * on (namespace, pod, cluster) group_left(node, host_ip, role) node_namespace_pod:kube_pod_info:) / node:node_num_cpu:sum
      record: node:load15:ratio
    - expr: |
        sum by (node, host_ip, role, cluster) ((kube_pod_status_scheduled{job="kube-state-metrics", condition="true"} > 0)  * on (namespace, pod, cluster) group_left(node, host_ip, role) node_namespace_pod:kube_pod_info:)
      record: node:pod_count:sum
    - expr: |
        (sum(kube_node_status_capacity{resource="pods", job="kube-state-metrics"}) by (node, cluster) * on(node, cluster) group_left(host_ip, role) max by(node, host_ip, role, cluster) (node_namespace_pod:kube_pod_info:{node!="",host_ip!=""}))
      record: node:pod_capacity:sum
    - expr: |
        node:pod_running:count / node:pod_capacity:sum
      record: node:pod_utilization:ratio
    - expr: |
        count(node_namespace_pod:kube_pod_info: unless on (pod, namespace, cluster) (kube_pod_status_phase{job="kube-state-metrics", phase=~"Failed|Pending|Unknown|Succeeded"} > 0)) by (node, host_ip, role, cluster)
      record: node:pod_running:count
    - expr: |
        count(node_namespace_pod:kube_pod_info: unless on (pod, namespace, cluster) (kube_pod_status_phase{job="kube-state-metrics", phase=~"Failed|Pending|Unknown|Running"} > 0)) by (node, host_ip, role, cluster)
      record: node:pod_succeeded:count
    - expr: |
        count(node_namespace_pod:kube_pod_info:{node!="",host_ip!=""} unless on (pod, namespace, cluster) (kube_pod_status_phase{job="kube-state-metrics", phase="Succeeded"}>0) unless on (pod, namespace, cluster) ((kube_pod_status_ready{job="kube-state-metrics", condition="true"}>0) and on (pod, namespace, cluster) (kube_pod_status_phase{job="kube-state-metrics", phase="Running"}>0)) unless on (pod, namespace, cluster) kube_pod_container_status_waiting_reason{job="kube-state-metrics", reason="ContainerCreating"}>0) by (node, host_ip, role, cluster)
      record: node:pod_abnormal:count
    - expr: |
        node:pod_abnormal:count / count(node_namespace_pod:kube_pod_info:{node!="",host_ip!=""} unless on (pod, namespace, cluster) kube_pod_status_phase{job="kube-state-metrics", phase="Succeeded"}>0) by (node, host_ip, role, cluster)
      record: node:pod_abnormal:ratio
    - expr: |
        sum(max(node_filesystem_avail_bytes{device=~"/dev/.*", device!~"/dev/loop\\d+", job="node-exporter"} * on (namespace, pod, cluster) group_left(node, host_ip, role) node_namespace_pod:kube_pod_info:) by (device, node, host_ip, role, cluster)) by (node, host_ip, role, cluster)
      record: 'node:disk_space_available:'
    - expr: |
        1- sum(max(node_filesystem_avail_bytes{device=~"/dev/.*", device!~"/dev/loop\\d+", job="node-exporter"} * on (namespace, pod, cluster) group_left(node, host_ip, role) node_namespace_pod:kube_pod_info:) by (device, node, host_ip, role, cluster)) by (node, host_ip, role, cluster) / sum(max(node_filesystem_size_bytes{device=~"/dev/.*", device!~"/dev/loop\\d+", job="node-exporter"} * on (namespace, pod, cluster) group_left(node, host_ip, role) node_namespace_pod:kube_pod_info:) by (device, node, host_ip, role, cluster)) by (node, host_ip, role, cluster)
      record: node:disk_space_utilization:ratio
    - expr: |
        (1 - (node:node_inodes_free: / node:node_inodes_total:))
      record: node:disk_inode_utilization:ratio
  - name: cluster.rules
    rules:
    - expr: |
        count by(cluster) (kube_pod_info{job="kube-state-metrics"} unless on (pod, namespace, cluster) (kube_pod_status_phase{job="kube-state-metrics", phase="Succeeded"}>0) unless on (pod, namespace, cluster) ((kube_pod_status_ready{job="kube-state-metrics", condition="true"}>0) and on (pod, namespace, cluster) (kube_pod_status_phase{job="kube-state-metrics", phase="Running"}>0)) unless on (pod, namespace, cluster) kube_pod_container_status_waiting_reason{job="kube-state-metrics", reason="ContainerCreating"}>0)
      record: cluster:pod_abnormal:sum
    - expr: |
        sum by(cluster) ((kube_pod_status_scheduled{job="kube-state-metrics", condition="true"} > 0)  * on (namespace, pod, cluster) group_left(node) (sum by (node, namespace, pod, cluster) (kube_pod_info)))
      record: cluster:pod:sum
    - expr: |
        cluster:pod_abnormal:sum / sum by(cluster) (kube_pod_status_phase{job="kube-state-metrics", phase!="Succeeded"})
      record: cluster:pod_abnormal:ratio
    - expr: |
        count by(cluster) (kube_pod_info{job="kube-state-metrics"} and on (pod, namespace, cluster) (kube_pod_status_phase{job="kube-state-metrics", phase="Running"}>0))
      record: cluster:pod_running:count
    - expr: |
        cluster:pod_running:count / sum by(cluster) (kube_node_status_capacity{resource="pods", job="kube-state-metrics"})
      record: cluster:pod_utilization:ratio
    - expr: |
        1 - sum by(cluster) (max(node_filesystem_avail_bytes{device=~"/dev/.*", device!~"/dev/loop\\d+", job="node-exporter"}) by (device, instance, cluster)) / sum by(cluster) (max(node_filesystem_size_bytes{device=~"/dev/.*", device!~"/dev/loop\\d+", job="node-exporter"}) by (device, instance, cluster))
      record: cluster:disk_utilization:ratio
    - expr: |
        1 - sum by(cluster) (node:node_inodes_free:) / sum by(cluster) (node:node_inodes_total:)
      record: cluster:disk_inode_utilization:ratio
    - expr: |
        sum by(cluster) (kube_node_status_condition{job="kube-state-metrics", condition="Ready", status=~"unknown|false"})
      record: cluster:node_offline:sum
    - expr: |
        sum by(cluster) (kube_node_status_condition{job="kube-state-metrics", condition="Ready", status=~"unknown|false"}) / sum by(cluster) (kube_node_status_condition{job="kube-state-metrics", condition="Ready"})
      record: cluster:node_offline:ratio
  - name: namespace.rules
    rules:
    - expr: |
        (count by(namespace, cluster) (kube_pod_info{job="kube-state-metrics"} unless on(pod, namespace, cluster) (kube_pod_status_phase{job="kube-state-metrics",phase="Succeeded"} > 0) unless on(pod, namespace, cluster) ((kube_pod_status_ready{condition="true",job="kube-state-metrics"} > 0) and on(pod, namespace, cluster) (kube_pod_status_phase{job="kube-state-metrics",phase="Running"} > 0)) unless on(pod, namespace, cluster) kube_pod_container_status_waiting_reason{job="kube-state-metrics",reason="ContainerCreating"} > 0) or on(namespace, cluster) (group by(namespace, cluster) (kube_pod_info{job="kube-state-metrics"}) * 0)) * on(namespace, cluster) group_left(workspace) (kube_namespace_labels{job="kube-state-metrics"}) > 0
      record: namespace:pod_abnormal:count
    - expr: |
        namespace:pod_abnormal:count / (sum(kube_pod_status_phase{job="kube-state-metrics", phase!="Succeeded", namespace!=""}) by (namespace, cluster) * on (namespace, cluster) group_left(workspace)(kube_namespace_labels{job="kube-state-metrics"}))
      record: namespace:pod_abnormal:ratio
    - expr: |
        max(kube_resourcequota{job="kube-state-metrics", type="used"}) by (resource, namespace, cluster) / min(kube_resourcequota{job="kube-state-metrics", type="hard"}) by (resource, namespace, cluster) *  on (namespace, cluster) group_left(workspace) (kube_namespace_labels{job="kube-state-metrics"})
      record: namespace:resourcequota_used:ratio
    - expr: |
        sum (label_replace(label_join(sum(irate(container_cpu_usage_seconds_total{job="kubelet", pod!="", image!=""}[5m])) by (namespace, pod, cluster) * on (pod, namespace, cluster) group_left(owner_kind,owner_name) label_replace(label_join(label_replace(label_replace(kube_pod_owner{job="kube-state-metrics"},"owner_kind", "Deployment", "owner_kind", "ReplicaSet"), "owner_kind", "Pod", "owner_kind", "<none>"),"tmp",":","owner_name","pod"),"owner_name","$1","tmp","<none>:(.*)"), "workload",":","owner_kind","owner_name"), "workload","$1","workload","(Deployment:.+)-(.+)")) by (namespace, workload, owner_kind, cluster)
      record: namespace:workload_cpu_usage:sum
    - expr: |
        sum (label_replace(label_join(sum(container_memory_usage_bytes{job="kubelet", pod!="", image!=""}) by (namespace, pod, cluster) * on (pod, namespace, cluster) group_left(owner_kind,owner_name) label_replace(label_join(label_replace(label_replace(kube_pod_owner{job="kube-state-metrics"},"owner_kind", "Deployment", "owner_kind", "ReplicaSet"), "owner_kind", "Pod", "owner_kind", "<none>"),"tmp",":","owner_name","pod"),"owner_name","$1","tmp","<none>:(.*)"), "workload",":","owner_kind","owner_name"), "workload","$1","workload","(Deployment:.+)-(.+)")) by (namespace, workload, owner_kind, cluster)
      record: namespace:workload_memory_usage:sum
    - expr: |
        sum (label_replace(label_join(sum(container_memory_working_set_bytes{job="kubelet", pod!="", image!=""}) by (namespace, pod, cluster) * on (pod, namespace, cluster) group_left(owner_kind,owner_name) label_replace(label_join(label_replace(label_replace(kube_pod_owner{job="kube-state-metrics"},"owner_kind", "Deployment", "owner_kind", "ReplicaSet"), "owner_kind", "Pod", "owner_kind", "<none>"),"tmp",":","owner_name","pod"),"owner_name","$1","tmp","<none>:(.*)"), "workload",":","owner_kind","owner_name"), "workload","$1","workload","(Deployment:.+)-(.+)")) by (namespace, workload, owner_kind, cluster)
      record: namespace:workload_memory_usage_wo_cache:sum
    - expr: |
        sum (label_replace(label_join(sum(irate(container_network_transmit_bytes_total{pod!="", interface!~"^(cali.+|tunl.+|dummy.+|kube.+|flannel.+|cni.+|docker.+|veth.+|lo.*)", job="kubelet"}[5m])) by (namespace, pod, cluster) * on (pod, namespace, cluster) group_left(owner_kind,owner_name) label_replace(label_join(label_replace(label_replace(kube_pod_owner{job="kube-state-metrics"},"owner_kind", "Deployment", "owner_kind", "ReplicaSet"), "owner_kind", "Pod", "owner_kind", "<none>"),"tmp",":","owner_name","pod"),"owner_name","$1","tmp","<none>:(.*)"), "workload",":","owner_kind","owner_name"), "workload","$1","workload","(Deployment:.+)-(.+)")) by (namespace, workload, owner_kind, cluster)
      record: namespace:workload_net_bytes_transmitted:sum_irate
    - expr: |
        sum (label_replace(label_join(sum(container_network_transmit_bytes_total{pod!="", interface!~"^(cali.+|tunl.+|dummy.+|kube.+|flannel.+|cni.+|docker.+|veth.+|lo.*)", job="kubelet"}) by (namespace, pod, cluster) * on (pod, namespace, cluster) group_left(owner_kind,owner_name) label_replace(label_join(label_replace(label_replace(kube_pod_owner{job="kube-state-metrics"},"owner_kind", "Deployment", "owner_kind", "ReplicaSet"), "owner_kind", "Pod", "owner_kind", "<none>"),"tmp",":","owner_name","pod"),"owner_name","$1","tmp","<none>:(.*)"), "workload",":","owner_kind","owner_name"), "workload","$1","workload","(Deployment:.+)-(.+)")) by (namespace, workload, owner_kind, cluster)
      record: namespace:workload_net_bytes_transmitted:sum
    - expr: |
        sum (label_replace(label_join(sum(irate(container_network_receive_bytes_total{pod!="", interface!~"^(cali.+|tunl.+|dummy.+|kube.+|flannel.+|cni.+|docker.+|veth.+|lo.*)", job="kubelet"}[5m])) by (namespace, pod, cluster) * on (pod, namespace, cluster) group_left(owner_kind,owner_name) label_replace(label_join(label_replace(label_replace(kube_pod_owner{job="kube-state-metrics"},"owner_kind", "Deployment", "owner_kind", "ReplicaSet"), "owner_kind", "Pod", "owner_kind", "<none>"),"tmp",":","owner_name","pod"),"owner_name","$1","tmp","<none>:(.*)"), "workload",":","owner_kind","owner_name"), "workload","$1","workload","(Deployment:.+)-(.+)")) by (namespace, workload, owner_kind, cluster)
      record: namespace:workload_net_bytes_received:sum_irate
    - expr: |
        sum (label_replace(label_join(sum(container_network_receive_bytes_total{pod!="", interface!~"^(cali.+|tunl.+|dummy.+|kube.+|flannel.+|cni.+|docker.+|veth.+|lo.*)", job="kubelet"}) by (namespace, pod, cluster) * on (pod, namespace, cluster) group_left(owner_kind,owner_name) label_replace(label_join(label_replace(label_replace(kube_pod_owner{job="kube-state-metrics"},"owner_kind", "Deployment", "owner_kind", "ReplicaSet"), "owner_kind", "Pod", "owner_kind", "<none>"),"tmp",":","owner_name","pod"),"owner_name","$1","tmp","<none>:(.*)"), "workload",":","owner_kind","owner_name"), "workload","$1","workload","(Deployment:.+)-(.+)")) by (namespace, workload, owner_kind, cluster)
      record: namespace:workload_net_bytes_received:sum
    - expr: |
        label_replace(label_replace(sum(kube_deployment_status_replicas_unavailable{job="kube-state-metrics"}) by (deployment, namespace, cluster) / sum(kube_deployment_spec_replicas{job="kube-state-metrics"}) by (deployment, namespace, cluster) * on (namespace, cluster) group_left(workspace)(kube_namespace_labels{job="kube-state-metrics"}), "workload","Deployment:$1", "deployment", "(.*)"), "owner_kind","Deployment", "", "")
      record: namespace:deployment_unavailable_replicas:ratio
    - expr: |
        label_replace(label_replace(sum(kube_daemonset_status_number_unavailable{job="kube-state-metrics"}) by (daemonset, namespace, cluster) / sum(kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"}) by (daemonset, namespace, cluster) * on (namespace, cluster) group_left(workspace)(kube_namespace_labels{job="kube-state-metrics"}) , "workload","DaemonSet:$1", "daemonset", "(.*)"), "owner_kind","DaemonSet", "", "")
      record: namespace:daemonset_unavailable_replicas:ratio
    - expr: |
        label_replace(label_replace((1 - sum(kube_statefulset_status_replicas_current{job="kube-state-metrics"}) by (statefulset, namespace, cluster) / sum(kube_statefulset_replicas{job="kube-state-metrics"}) by (statefulset, namespace, cluster)) * on (namespace, cluster) group_left(workspace)(kube_namespace_labels{job="kube-state-metrics"}) , "workload","StatefulSet:$1", "statefulset", "(.*)"), "owner_kind","StatefulSet", "", "")
      record: namespace:statefulset_unavailable_replicas:ratio
    - expr: |
        sum(kube_pod_container_resource_requests * on (pod, namespace, cluster) group_left(owner_kind,owner_name) label_replace(label_join(label_replace(label_replace(kube_pod_owner{job="kube-state-metrics"},"owner_kind","Deployment","owner_kind","ReplicaSet"),"owner_kind","Pod","owner_kind","<none>"),"tmp",":","owner_name","pod"),"owner_name","$1","tmp","<none>:(.*)")) by (namespace, owner_kind, pod, resource, cluster)* on(namespace, cluster) group_left(workspace)kube_namespace_labels{job="kube-state-metrics"}
      record: namespace:kube_pod_resource_request:sum
    - expr: |
        sum(label_replace(label_join(kube_pod_container_resource_requests * on (pod, namespace, cluster) group_left(owner_kind,owner_name)label_replace(label_join(label_replace(label_replace(kube_pod_owner{job="kube-state-metrics"},"owner_kind","Deployment","owner_kind","ReplicaSet"),"owner_kind","Pod","owner_kind","<none>"),"tmp",":","owner_name","pod"),"owner_name","$1","tmp","<none>:(.*)"),"workload",":","owner_kind","owner_name"),"workload","$1","workload","(Deployment:.+)-(.+)")) by (namespace, workload, resource, cluster)* on(namespace, cluster) group_left(workspace) kube_namespace_labels{job="kube-state-metrics"}
      record: namespace:kube_workload_resource_request:sum
    - expr: |
        sum(label_replace(label_join(kube_pod_spec_volumes_persistentvolumeclaims_info * on (pod, namespace, cluster) group_left(owner_kind,owner_name)label_replace(label_join(label_replace(label_replace(kube_pod_owner{job="kube-state-metrics"},"owner_kind","Deployment","owner_kind","ReplicaSet"),"owner_kind","Pod","owner_kind","<none>"),"tmp",":","owner_name","pod"),"owner_name","$1","tmp","<none>:(.*)"),"workload",":","owner_kind","owner_name"),"workload","$1","workload","(Deployment:.+)-(.+)")) by (namespace, workload, pod, persistentvolumeclaim, cluster)* on(namespace, pod, cluster) group_left(node) kube_pod_info{job="kube-state-metrics"}* on (node, persistentvolumeclaim, namespace, cluster) group_left kubelet_volume_stats_capacity_bytes * on(namespace, cluster) group_left(workspace) kube_namespace_labels{job="kube-state-metrics"}
      record: namespace:pvc_bytes_total:sum
  - name: apiserver.rules
    rules:
    - expr: |
        sum by(cluster) (up{job="apiserver"} == 1)
      record: apiserver:up:sum
    - expr: |
        sum by(cluster) (irate(apiserver_request_total{job="apiserver"}[5m]))
      record: apiserver:apiserver_request_total:sum_irate
    - expr: |
        sum(irate(apiserver_request_total{job="apiserver"}[5m])) by (verb, cluster)
      record: apiserver:apiserver_request_total:sum_verb_irate
    - expr: |
        sum by(cluster) (irate(apiserver_request_duration_seconds_sum{job="apiserver",subresource!="log", verb!~"LIST|WATCH|WATCHLIST|PROXY|CONNECT"}[5m])) / sum by(cluster) (irate(apiserver_request_duration_seconds_count{job="apiserver", subresource!="log",verb!~"LIST|WATCH|WATCHLIST|PROXY|CONNECT"}[5m]))
      record: apiserver:apiserver_request_duration:avg
    - expr: |
        sum(irate(apiserver_request_duration_seconds_sum{job="apiserver",subresource!="log", verb!~"LIST|WATCH|WATCHLIST|PROXY|CONNECT"}[5m])) by (verb, cluster) / sum(irate(apiserver_request_duration_seconds_count{job="apiserver", subresource!="log",verb!~"LIST|WATCH|WATCHLIST|PROXY|CONNECT"}[5m])) by (verb, cluster)
      record: apiserver:apiserver_request_duration:avg_by_verb
  - name: scheduler.rules
    rules:
    - expr: |
        sum by(cluster) (up{job="kube-scheduler"} == 1)
      record: scheduler:up:sum
    - expr: |
        sum(scheduler_schedule_attempts_total{job="kube-scheduler"}) by (result, cluster)
      record: scheduler:scheduler_schedule_attempts:sum
    - expr: |
        sum(rate(scheduler_schedule_attempts_total{job="kube-scheduler"}[5m])) by (result, cluster)
      record: scheduler:scheduler_schedule_attempts:sum_rate
    - expr: |
        (sum by(cluster) (rate(scheduler_e2e_scheduling_duration_seconds_sum{job="kube-scheduler"}[1h]))  / sum by(cluster) (rate(scheduler_e2e_scheduling_duration_seconds_count{job="kube-scheduler"}[1h])))
      record: scheduler:scheduler_e2e_scheduling_duration:avg
  - name: scheduler_histogram.rules
    rules:
    - expr: |
        histogram_quantile(0.99, sum(rate(scheduler_e2e_scheduling_duration_seconds_bucket{job="kube-scheduler"}[1h])) by (le, cluster) )
      labels:
        quantile: "0.99"
      record: scheduler:scheduler_e2e_scheduling_duration:histogram_quantile
    - expr: |
        histogram_quantile(0.9, sum(rate(scheduler_e2e_scheduling_duration_seconds_bucket{job="kube-scheduler"}[1h])) by (le, cluster) )
      labels:
        quantile: "0.9"
      record: scheduler:scheduler_e2e_scheduling_duration:histogram_quantile
    - expr: |
        histogram_quantile(0.5, sum(rate(scheduler_e2e_scheduling_duration_seconds_bucket{job="kube-scheduler"}[1h])) by (le, cluster) )
      labels:
        quantile: "0.5"
      record: scheduler:scheduler_e2e_scheduling_duration:histogram_quantile
  - name: controller_manager.rules
    rules:
    - expr: |
        sum by(cluster) (up{job="kube-controller-manager"} == 1)
      record: controller_manager:up:sum
  - name: coredns.rules
    rules:
    - expr: |
        sum by(cluster) (up{job="coredns"} == 1)
      record: coredns:up:sum
  - name: kube-apiserver-burnrate.rules
    rules:
    - expr: |
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"LIST|GET"}[1d]))
            -
            (
              (
                sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope=~"resource|",le="1"}[1d]))
                or
                vector(0)
              )
              +
              sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="namespace",le="5"}[1d]))
              +
              sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="cluster",le="30"}[1d]))
            )
          )
          +
          # errors
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[1d]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[1d]))
      labels:
        verb: read
      record: apiserver_request:burnrate1d
    - expr: |
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"LIST|GET"}[1h]))
            -
            (
              (
                sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope=~"resource|",le="1"}[1h]))
                or
                vector(0)
              )
              +
              sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="namespace",le="5"}[1h]))
              +
              sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="cluster",le="30"}[1h]))
            )
          )
          +
          # errors
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[1h]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[1h]))
      labels:
        verb: read
      record: apiserver_request:burnrate1h
    - expr: |
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"LIST|GET"}[2h]))
            -
            (
              (
                sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope=~"resource|",le="1"}[2h]))
                or
                vector(0)
              )
              +
              sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="namespace",le="5"}[2h]))
              +
              sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="cluster",le="30"}[2h]))
            )
          )
          +
          # errors
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[2h]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[2h]))
      labels:
        verb: read
      record: apiserver_request:burnrate2h
    - expr: |
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"LIST|GET"}[30m]))
            -
            (
              (
                sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope=~"resource|",le="1"}[30m]))
                or
                vector(0)
              )
              +
              sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="namespace",le="5"}[30m]))
              +
              sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="cluster",le="30"}[30m]))
            )
          )
          +
          # errors
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[30m]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[30m]))
      labels:
        verb: read
      record: apiserver_request:burnrate30m
    - expr: |
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"LIST|GET"}[3d]))
            -
            (
              (
                sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope=~"resource|",le="1"}[3d]))
                or
                vector(0)
              )
              +
              sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="namespace",le="5"}[3d]))
              +
              sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="cluster",le="30"}[3d]))
            )
          )
          +
          # errors
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[3d]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[3d]))
      labels:
        verb: read
      record: apiserver_request:burnrate3d
    - expr: |
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"LIST|GET"}[5m]))
            -
            (
              (
                sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope=~"resource|",le="1"}[5m]))
                or
                vector(0)
              )
              +
              sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="namespace",le="5"}[5m]))
              +
              sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="cluster",le="30"}[5m]))
            )
          )
          +
          # errors
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[5m]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[5m]))
      labels:
        verb: read
      record: apiserver_request:burnrate5m
    - expr: |
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"LIST|GET"}[6h]))
            -
            (
              (
                sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope=~"resource|",le="1"}[6h]))
                or
                vector(0)
              )
              +
              sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="namespace",le="5"}[6h]))
              +
              sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="cluster",le="30"}[6h]))
            )
          )
          +
          # errors
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[6h]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[6h]))
      labels:
        verb: read
      record: apiserver_request:burnrate6h
    - expr: |
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[1d]))
            -
            sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",le="1"}[1d]))
          )
          +
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[1d]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[1d]))
      labels:
        verb: write
      record: apiserver_request:burnrate1d
    - expr: |
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[1h]))
            -
            sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",le="1"}[1h]))
          )
          +
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[1h]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[1h]))
      labels:
        verb: write
      record: apiserver_request:burnrate1h
    - expr: |
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[2h]))
            -
            sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",le="1"}[2h]))
          )
          +
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[2h]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[2h]))
      labels:
        verb: write
      record: apiserver_request:burnrate2h
    - expr: |
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[30m]))
            -
            sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",le="1"}[30m]))
          )
          +
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[30m]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[30m]))
      labels:
        verb: write
      record: apiserver_request:burnrate30m
    - expr: |
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[3d]))
            -
            sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",le="1"}[3d]))
          )
          +
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[3d]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[3d]))
      labels:
        verb: write
      record: apiserver_request:burnrate3d
    - expr: |
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[5m]))
            -
            sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",le="1"}[5m]))
          )
          +
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[5m]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[5m]))
      labels:
        verb: write
      record: apiserver_request:burnrate5m
    - expr: |
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[6h]))
            -
            sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",le="1"}[6h]))
          )
          +
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[6h]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[6h]))
      labels:
        verb: write
      record: apiserver_request:burnrate6h
  - name: kube-apiserver-histogram.rules
    rules:
    - expr: |
        histogram_quantile(0.99, sum by (cluster, le, resource) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET"}[5m]))) > 0
      labels:
        quantile: "0.99"
        verb: read
      record: cluster_quantile:apiserver_request_duration_seconds:histogram_quantile
    - expr: |
        histogram_quantile(0.99, sum by (cluster, le, resource) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[5m]))) > 0
      labels:
        quantile: "0.99"
        verb: write
      record: cluster_quantile:apiserver_request_duration_seconds:histogram_quantile
    - expr: |
        histogram_quantile(0.99, sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",subresource!="log",verb!~"LIST|WATCH|WATCHLIST|DELETECOLLECTION|PROXY|CONNECT"}[5m])) without(instance, pod))
      labels:
        quantile: "0.99"
      record: cluster_quantile:apiserver_request_duration_seconds:histogram_quantile
    - expr: |
        histogram_quantile(0.9, sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",subresource!="log",verb!~"LIST|WATCH|WATCHLIST|DELETECOLLECTION|PROXY|CONNECT"}[5m])) without(instance, pod))
      labels:
        quantile: "0.9"
      record: cluster_quantile:apiserver_request_duration_seconds:histogram_quantile
    - expr: |
        histogram_quantile(0.5, sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",subresource!="log",verb!~"LIST|WATCH|WATCHLIST|DELETECOLLECTION|PROXY|CONNECT"}[5m])) without(instance, pod))
      labels:
        quantile: "0.5"
      record: cluster_quantile:apiserver_request_duration_seconds:histogram_quantile
  - interval: 3m
    name: kube-apiserver-availability.rules
    rules:
    - expr: |
        avg_over_time(code_verb:apiserver_request_total:increase1h[30d]) * 24 * 30
      record: code_verb:apiserver_request_total:increase30d
    - expr: |
        sum by (cluster, code) (code_verb:apiserver_request_total:increase30d{verb=~"LIST|GET"})
      labels:
        verb: read
      record: code:apiserver_request_total:increase30d
    - expr: |
        sum by (cluster, code) (code_verb:apiserver_request_total:increase30d{verb=~"POST|PUT|PATCH|DELETE"})
      labels:
        verb: write
      record: code:apiserver_request_total:increase30d
    - expr: |
        sum by (cluster, verb, scope) (increase(apiserver_request_duration_seconds_count[1h]))
      record: cluster_verb_scope:apiserver_request_duration_seconds_count:increase1h
    - expr: |
        sum by (cluster, verb, scope) (avg_over_time(cluster_verb_scope:apiserver_request_duration_seconds_count:increase1h[30d]) * 24 * 30)
      record: cluster_verb_scope:apiserver_request_duration_seconds_count:increase30d
    - expr: |
        sum by (cluster, verb, scope, le) (increase(apiserver_request_duration_seconds_bucket[1h]))
      record: cluster_verb_scope_le:apiserver_request_duration_seconds_bucket:increase1h
    - expr: |
        sum by (cluster, verb, scope, le) (avg_over_time(cluster_verb_scope_le:apiserver_request_duration_seconds_bucket:increase1h[30d]) * 24 * 30)
      record: cluster_verb_scope_le:apiserver_request_duration_seconds_bucket:increase30d
    - expr: |
        1 - (
          (
            # write too slow
            sum by (cluster) (cluster_verb_scope:apiserver_request_duration_seconds_count:increase30d{verb=~"POST|PUT|PATCH|DELETE"})
            -
            sum by (cluster) (cluster_verb_scope_le:apiserver_request_duration_seconds_bucket:increase30d{verb=~"POST|PUT|PATCH|DELETE",le="1"})
          ) +
          (
            # read too slow
            sum by (cluster) (cluster_verb_scope:apiserver_request_duration_seconds_count:increase30d{verb=~"LIST|GET"})
            -
            (
              (
                sum by (cluster) (cluster_verb_scope_le:apiserver_request_duration_seconds_bucket:increase30d{verb=~"LIST|GET",scope=~"resource|",le="1"})
                or
                vector(0)
              )
              +
              sum by (cluster) (cluster_verb_scope_le:apiserver_request_duration_seconds_bucket:increase30d{verb=~"LIST|GET",scope="namespace",le="5"})
              +
              sum by (cluster) (cluster_verb_scope_le:apiserver_request_duration_seconds_bucket:increase30d{verb=~"LIST|GET",scope="cluster",le="30"})
            )
          ) +
          # errors
          sum by (cluster) (code:apiserver_request_total:increase30d{code=~"5.."} or vector(0))
        )
        /
        sum by (cluster) (code:apiserver_request_total:increase30d)
      labels:
        verb: all
      record: apiserver_request:availability30d
    - expr: |
        1 - (
          sum by (cluster) (cluster_verb_scope:apiserver_request_duration_seconds_count:increase30d{verb=~"LIST|GET"})
          -
          (
            # too slow
            (
              sum by (cluster) (cluster_verb_scope_le:apiserver_request_duration_seconds_bucket:increase30d{verb=~"LIST|GET",scope=~"resource|",le="1"})
              or
              vector(0)
            )
            +
            sum by (cluster) (cluster_verb_scope_le:apiserver_request_duration_seconds_bucket:increase30d{verb=~"LIST|GET",scope="namespace",le="5"})
            +
            sum by (cluster) (cluster_verb_scope_le:apiserver_request_duration_seconds_bucket:increase30d{verb=~"LIST|GET",scope="cluster",le="30"})
          )
          +
          # errors
          sum by (cluster) (code:apiserver_request_total:increase30d{verb="read",code=~"5.."} or vector(0))
        )
        /
        sum by (cluster) (code:apiserver_request_total:increase30d{verb="read"})
      labels:
        verb: read
      record: apiserver_request:availability30d
    - expr: |
        1 - (
          (
            # too slow
            sum by (cluster) (cluster_verb_scope:apiserver_request_duration_seconds_count:increase30d{verb=~"POST|PUT|PATCH|DELETE"})
            -
            sum by (cluster) (cluster_verb_scope_le:apiserver_request_duration_seconds_bucket:increase30d{verb=~"POST|PUT|PATCH|DELETE",le="1"})
          )
          +
          # errors
          sum by (cluster) (code:apiserver_request_total:increase30d{verb="write",code=~"5.."} or vector(0))
        )
        /
        sum by (cluster) (code:apiserver_request_total:increase30d{verb="write"})
      labels:
        verb: write
      record: apiserver_request:availability30d
    - expr: |
        sum by (cluster,code,resource) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[5m]))
      labels:
        verb: read
      record: code_resource:apiserver_request_total:rate5m
    - expr: |
        sum by (cluster,code,resource) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[5m]))
      labels:
        verb: write
      record: code_resource:apiserver_request_total:rate5m
    - expr: |
        sum by (cluster, code, verb) (increase(apiserver_request_total{job="apiserver",verb=~"LIST|GET|POST|PUT|PATCH|DELETE",code=~"2.."}[1h]))
      record: code_verb:apiserver_request_total:increase1h
    - expr: |
        sum by (cluster, code, verb) (increase(apiserver_request_total{job="apiserver",verb=~"LIST|GET|POST|PUT|PATCH|DELETE",code=~"3.."}[1h]))
      record: code_verb:apiserver_request_total:increase1h
    - expr: |
        sum by (cluster, code, verb) (increase(apiserver_request_total{job="apiserver",verb=~"LIST|GET|POST|PUT|PATCH|DELETE",code=~"4.."}[1h]))
      record: code_verb:apiserver_request_total:increase1h
    - expr: |
        sum by (cluster, code, verb) (increase(apiserver_request_total{job="apiserver",verb=~"LIST|GET|POST|PUT|PATCH|DELETE",code=~"5.."}[1h]))
      record: code_verb:apiserver_request_total:increase1h
  - name: kubelet.rules
    rules:
    - expr: |
        histogram_quantile(0.99, sum(rate(kubelet_pleg_relist_duration_seconds_bucket[5m])) by (instance, le, cluster) * on(instance, cluster) group_left(node) kubelet_node_name{job="kubelet"})
      labels:
        quantile: "0.99"
      record: node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile
    - expr: |
        histogram_quantile(0.9, sum(rate(kubelet_pleg_relist_duration_seconds_bucket[5m])) by (instance, le, cluster) * on(instance, cluster) group_left(node) kubelet_node_name{job="kubelet"})
      labels:
        quantile: "0.9"
      record: node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile
    - expr: |
        histogram_quantile(0.5, sum(rate(kubelet_pleg_relist_duration_seconds_bucket[5m])) by (instance, le, cluster) * on(instance, cluster) group_left(node) kubelet_node_name{job="kubelet"})
      labels:
        quantile: "0.5"
      record: node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile
